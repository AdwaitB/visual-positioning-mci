{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a63dacf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe80947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd1809",
   "metadata": {},
   "source": [
    "## Stage 1\n",
    "For the first stage, we had to create a CSV file with each row having a timestamp, followed by 9 values of sensors. The difficulty here is that the onSensorChanged method gives us a SensorEvent object corresponding to one sensor that has timestamp and the value for that particular sensor. Hence, we needed to implement a bucketing mechanism which divides the timeline into buckets, and all sensor values for a particular sensor that fall within a bucket are averaged out. This functionality is implemented in the **ReadingBucket** class in sensorcapture folder.\n",
    "\n",
    "We tried 5 buckets corresponding to bucket sizes of 1, 5, 10, 20 and 50 milliseconds.\n",
    "On running plot_stage_1(), the plots for the magnitude of acceleration (taken from vector sum of accerelations in the x, y and z axes) versus time are displayed. The activity we were doing while taking readings was simple walking.\n",
    "\n",
    "The thing to note is that the graphs match up with each other very well. This proves that there is no loss of information in our bucketing mechanism.\n",
    "\n",
    "**Deliverables**: The csv files corresponding to the data asked in stage 1 is stored in Stage 1 folder. You are free to check any csv file in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17196cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_stage_1():\n",
    "    BUCKET_SIZES = ['1','5','10','20','50']\n",
    "    for bucket_size in BUCKET_SIZES:\n",
    "        df = pd.read_csv('./Stage 1/' + bucket_size + '_data.csv')\n",
    "        df[str(bucket_size) + '_' + 'mag_acc'] = np.sqrt(pow(df['acc_x'],2)+pow(df['acc_y'],2)+pow(df['acc_z'],2))\n",
    "        \n",
    "        df[df['Timestamp'] > 40000].plot(x='Timestamp', y=str(bucket_size) + '_' + 'mag_acc', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027efa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7150dfda8b740fe97da07a3d5cb7bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e62995cbe9442debd7130d465861c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb395b78950847d68714b03b274d27ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a85c856b97d4d10b9310e966059fbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fa20eab043442c8507ed7ba5546808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stage_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103224b",
   "metadata": {},
   "source": [
    "___\n",
    "## Stage 2\n",
    "\n",
    "We used the program implemented in stage 1 to take readings for 5 different activities while holding the phone in the manner described in the assignment PDF. We used a 25 metre long corridor for walking, running. Jumping and idling were done in one place. Stairs was done by walking down two flights of 8 stairs each.\n",
    "\n",
    "**Deliverables**: The csv files corresponding to the five activities can be found in the Stage 2 folder. We have used files corresponding to bucket size 50 for this. Note that there is no loss of information due to bucket size 50, as demonstrated above.\n",
    "Note: The file names do not match the exact format specified in the assignment because of the host OS not allowing files to have certain characters like : colon and - hyphen . The format we are using is LABEL ddmmyyhhmmss DISTANCE.csv The activity Stairs has no distance associated with it.\n",
    "\n",
    "On running plot_stage_2(), you will find the plots for the magnitude of acceleration for each of the activities. We will attempt to distinguish them later in stage 4. For now, it suffices to understand that Idle has the lowest range of acceleration magnitude due to the phone just being stationary. The range of Stairs and Walking is similar, however the curves are qualitatively different. Running and Jumping have far higher ranges than the previous three, with Jumping having the noticeably largest range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bd00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stage_2():\n",
    "    ACTIVITIES = ['Idle', 'Stairs', 'Walking', 'Running', 'Jumping']\n",
    "    for activity in ACTIVITIES:\n",
    "        df = pd.read_csv('./Stage 2/' + activity + '/' + os.popen('ls ./Stage\\ 2/' + activity).read()[:-1])\n",
    "        df[activity + '_mag_acc'] = np.sqrt(pow(df['acc_x'],2)+pow(df['acc_y'],2)+pow(df['acc_z'],2))\n",
    "        df.plot(x='Timestamp', y = activity + '_mag_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0819a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0731167c2a47f7bb78117d282ad2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198617dc813f4050951c19bd96724798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2754e2c1e7f4479a99a1d11828450efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a80eb635e16457e8381c8bfeec6ce8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25292f323834b009085869788d44924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stage_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23538321",
   "metadata": {},
   "source": [
    "___\n",
    "## Stage 3\n",
    "\n",
    "For implementing the stage detection algorithm, we use the method of Windowed-Peak detection as described in the paper [An Optimised Algorithm for Accurate Steps Counting From Smart-Phone Accelerometry (2013)](https://www.researchgate.net/publication/328990649_An_Optimised_Algorithm_for_Accurate_Steps_Counting_From_Smart-Phone_Accelerometry) in Conference: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC).\n",
    "\n",
    "The algorithm takes the magnitude of the acceleration (resultant vector of accelerations in the x, y and z axes) as an input signal and performs 3 stages of processing on it to detect steps. A step is detected by looking at the peaks in the signal.\n",
    "\n",
    "The algorithm can be described in a concise manner as follows:\n",
    "1. Stage 1 (Smoothening) : Apply a smoothening process to clean the input signal and remove noise\n",
    "2. Stage 2 (Exaggeration) : Make the peaks in the signal exaggerated, to ensure that it is easy to detect a peak.\n",
    "3. Stage 3 (Detection) : Compute running averages for mean and standard deviation. Determine a candidate peak by checking if it's acceleration is a threshold number of standard deviations away from the mean. Ensure that you are picking only one peak (the maximum magnitude peak) in a window of time 200 milliseconds.\n",
    "![Visual depiction](algodescription.png)\n",
    "\n",
    "Implementation details:\n",
    "We have implemented each stage as a separate thread in our Android Studio code. This kept our code organized and ensured easy debugging. Each stage is connected to the next stage via queues to ensure passing of sensor readings between stages. The parameters we have used (such as detection window size, detection threshold value, parameters for implementing low pass filters) have all been optimized using a grid search done by the authors of the paper. The values of the parameters that gave the least Mean Absolute Error have been reported by the authors and used by us in our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053ef08",
   "metadata": {},
   "source": [
    "___\n",
    "## Stage 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1c7be",
   "metadata": {},
   "source": [
    "### Create a merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0452a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITIES = ['Idle','Stairs','Walking','Running','Jumping']\n",
    "merged_df = pd.DataFrame()\n",
    "for activity in ACTIVITIES:\n",
    "    df = pd.read_csv('./Stage 2/' + activity + '/' + os.popen('ls ./Stage\\ 2/' + activity).read()[:-1])\n",
    "    df[activity + '_mag_acc'] = np.sqrt(pow(df['acc_x'],2)+pow(df['acc_y'],2)+pow(df['acc_z'],2))\n",
    "        \n",
    "    if len(merged_df.index) == 0:\n",
    "        merged_df = df[['Timestamp', activity + '_mag_acc']]\n",
    "    else:\n",
    "        merged_df = pd.merge(merged_df, df[['Timestamp', activity + '_mag_acc']], on='Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddc8aa",
   "metadata": {},
   "source": [
    "### Group the merged dataframe into 0.2 second interval buckets as asked in the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b38870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idle_mag_acc</th>\n",
       "      <th>Stairs_mag_acc</th>\n",
       "      <th>Walking_mag_acc</th>\n",
       "      <th>Running_mag_acc</th>\n",
       "      <th>Jumping_mag_acc</th>\n",
       "      <th>Timestamp bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.624017</td>\n",
       "      <td>10.434484</td>\n",
       "      <td>9.056992</td>\n",
       "      <td>10.797216</td>\n",
       "      <td>10.161197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.039930</td>\n",
       "      <td>9.472214</td>\n",
       "      <td>10.227631</td>\n",
       "      <td>9.180802</td>\n",
       "      <td>9.833567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.849172</td>\n",
       "      <td>10.625443</td>\n",
       "      <td>10.194538</td>\n",
       "      <td>10.357861</td>\n",
       "      <td>10.119053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.914729</td>\n",
       "      <td>10.020754</td>\n",
       "      <td>8.957774</td>\n",
       "      <td>10.771258</td>\n",
       "      <td>10.067268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.867538</td>\n",
       "      <td>9.682949</td>\n",
       "      <td>10.435664</td>\n",
       "      <td>9.252519</td>\n",
       "      <td>9.846488</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9.879681</td>\n",
       "      <td>9.684747</td>\n",
       "      <td>13.552982</td>\n",
       "      <td>9.328849</td>\n",
       "      <td>3.311849</td>\n",
       "      <td>14800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>9.971253</td>\n",
       "      <td>9.470416</td>\n",
       "      <td>8.801763</td>\n",
       "      <td>13.025025</td>\n",
       "      <td>1.974191</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>9.816581</td>\n",
       "      <td>9.642601</td>\n",
       "      <td>9.356137</td>\n",
       "      <td>8.134215</td>\n",
       "      <td>4.747126</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>9.889863</td>\n",
       "      <td>9.320292</td>\n",
       "      <td>9.501930</td>\n",
       "      <td>5.030679</td>\n",
       "      <td>4.399159</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>9.951907</td>\n",
       "      <td>10.857919</td>\n",
       "      <td>7.398799</td>\n",
       "      <td>5.276553</td>\n",
       "      <td>12.349009</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Idle_mag_acc  Stairs_mag_acc  Walking_mag_acc  Running_mag_acc  \\\n",
       "0        9.624017       10.434484         9.056992        10.797216   \n",
       "1       10.039930        9.472214        10.227631         9.180802   \n",
       "2        9.849172       10.625443        10.194538        10.357861   \n",
       "3        9.914729       10.020754         8.957774        10.771258   \n",
       "4        9.867538        9.682949        10.435664         9.252519   \n",
       "..            ...             ...              ...              ...   \n",
       "299      9.879681        9.684747        13.552982         9.328849   \n",
       "300      9.971253        9.470416         8.801763        13.025025   \n",
       "301      9.816581        9.642601         9.356137         8.134215   \n",
       "302      9.889863        9.320292         9.501930         5.030679   \n",
       "303      9.951907       10.857919         7.398799         5.276553   \n",
       "\n",
       "     Jumping_mag_acc  Timestamp bucket  \n",
       "0          10.161197                 0  \n",
       "1           9.833567                 0  \n",
       "2          10.119053                 0  \n",
       "3          10.067268                 0  \n",
       "4           9.846488               200  \n",
       "..               ...               ...  \n",
       "299         3.311849             14800  \n",
       "300         1.974191             15000  \n",
       "301         4.747126             15000  \n",
       "302         4.399159             15000  \n",
       "303        12.349009             15000  \n",
       "\n",
       "[304 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Timestamp bucket'] = (merged_df['Timestamp'] // 200) * 200\n",
    "merged_df = merged_df.drop('Timestamp', 1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c767847",
   "metadata": {},
   "source": [
    "### Compute mean, median, max, variance, and zero-crossings for the intervals\n",
    "\n",
    "Note: Although we have written the code to compute zero crossings, zero crossings makes no sense for our case since the magnitude of acceleration will never ever go below zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635ff6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_merged_df_mean = merged_df.groupby(['Timestamp bucket']).mean()\n",
    "grouped_merged_df_mean = grouped_merged_df_mean.rename(columns={'Walking_mag_acc':'Walking_mag_acc_mean','Running_mag_acc':'Running_mag_acc_mean','Jumping_mag_acc':'Jumping_mag_acc_mean','Stairs_mag_acc':'Stairs_mag_acc_mean','Idle_mag_acc':'Idle_mag_acc_mean'})\n",
    "\n",
    "grouped_merged_df_median = merged_df.groupby(['Timestamp bucket']).median()\n",
    "grouped_merged_df_median = grouped_merged_df_median.rename(columns={'Walking_mag_acc':'Walking_mag_acc_median','Running_mag_acc':'Running_mag_acc_median','Jumping_mag_acc':'Jumping_mag_acc_median','Stairs_mag_acc':'Stairs_mag_acc_median','Idle_mag_acc':'Idle_mag_acc_median'})\n",
    "\n",
    "grouped_merged_df_max = merged_df.groupby(['Timestamp bucket']).max()\n",
    "grouped_merged_df_max = grouped_merged_df_max.rename(columns={'Walking_mag_acc':'Walking_mag_acc_max','Running_mag_acc':'Running_mag_acc_max','Jumping_mag_acc':'Jumping_mag_acc_max','Stairs_mag_acc':'Stairs_mag_acc_max','Idle_mag_acc':'Idle_mag_acc_max'})\n",
    "\n",
    "grouped_merged_df_variance = merged_df.groupby(['Timestamp bucket']).var()\n",
    "grouped_merged_df_variance = grouped_merged_df_variance.rename(columns={'Walking_mag_acc':'Walking_mag_acc_variance','Running_mag_acc':'Running_mag_acc_variance','Jumping_mag_acc':'Jumping_mag_acc_variance','Stairs_mag_acc':'Stairs_mag_acc_variance','Idle_mag_acc':'Idle_mag_acc_variance'})\n",
    "\n",
    "grouped_merged_df_walking_zerocrossings = pd.DataFrame(columns=['Timestamp bucket', 'Walking_mag_acc_zerocrossings'])\n",
    "for i in range(0,len(merged_df.index), 4):\n",
    "    count = 0\n",
    "    for j in range(i, i + 3):\n",
    "        if merged_df['Walking_mag_acc'][i] * merged_df['Walking_mag_acc'][i+1] < 0:\n",
    "            count += 1\n",
    "    grouped_merged_df_walking_zerocrossings.loc[len(grouped_merged_df_walking_zerocrossings.index)] = [merged_df['Timestamp bucket'][i], count] \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de197f4",
   "metadata": {},
   "source": [
    "### Merge all dataframes for ease of plotting and apply tags to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923f6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_merge = pd.merge(pd.merge(pd.merge(grouped_merged_df_mean, grouped_merged_df_median, on='Timestamp bucket'), grouped_merged_df_max, on='Timestamp bucket'), grouped_merged_df_variance, on='Timestamp bucket') \n",
    "\n",
    "walking_merge = mega_merge[['Walking_mag_acc_mean', 'Walking_mag_acc_median', 'Walking_mag_acc_max', 'Walking_mag_acc_variance']].copy()\n",
    "running_merge = mega_merge[['Running_mag_acc_mean', 'Running_mag_acc_median', 'Running_mag_acc_max', 'Running_mag_acc_variance']].copy()\n",
    "jumping_merge = mega_merge[['Jumping_mag_acc_mean', 'Jumping_mag_acc_median', 'Jumping_mag_acc_max', 'Jumping_mag_acc_variance']].copy()\n",
    "stairs_merge = mega_merge[['Stairs_mag_acc_mean', 'Stairs_mag_acc_median', 'Stairs_mag_acc_max', 'Stairs_mag_acc_variance']].copy()\n",
    "idle_merge = mega_merge[['Idle_mag_acc_mean', 'Idle_mag_acc_median', 'Idle_mag_acc_max', 'Idle_mag_acc_variance']].copy()\n",
    "\n",
    "tag = ['walking' for x in range(len(walking_merge.index))]\n",
    "walking_merge['tag'] = tag\n",
    "tag = ['running' for x in range(len(running_merge.index))]\n",
    "running_merge['tag'] = tag\n",
    "tag = ['jumping' for x in range(len(jumping_merge.index))]\n",
    "jumping_merge['tag'] = tag\n",
    "tag = ['stairs' for x in range(len(stairs_merge.index))]\n",
    "stairs_merge['tag'] = tag\n",
    "tag = ['idle' for x in range(len(idle_merge.index))]\n",
    "idle_merge['tag'] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a437a8",
   "metadata": {},
   "source": [
    "## Plotting the activities\n",
    "We can see from the graph that Jumping is the most spread out activity owing to high variance, followed by Running. Stairs and Walking are very similar. All the idle points are concentrated in a black dot, which you can view better by running the code and dragging things around. We are providing different views of the 3D plot, followed by one view where we plot only Jumping and Idle, to help better view Idle.\n",
    "\n",
    "Jumping and Idle (black circle shows Idle dots) : ![view1.png](view1.png)\n",
    "All activities : ![view2.png](view2.png)\n",
    "All activities (different view) : ![view3.png](view3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256ca882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8644b5b94667402aba722608d2d37e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = plt.figure(figsize=(6,6))\n",
    "plot = plt.axes(projection='3d')\n",
    "\n",
    "merge_dict = {}\n",
    "merge_dict['Jumping'] = jumping_merge\n",
    "merge_dict['Running'] = running_merge\n",
    "merge_dict['Walking'] = walking_merge\n",
    "merge_dict['Stairs'] = stairs_merge\n",
    "merge_dict['Idle'] = idle_merge\n",
    "\n",
    "color = {}\n",
    "color['Jumping'] = 'blue'\n",
    "color['Running'] = 'red'\n",
    "color['Walking'] = 'orange'\n",
    "color['Stairs'] = 'green'\n",
    "color['Idle'] = 'black'\n",
    "\n",
    "def plot_stage_4(activities, features):\n",
    "    for activity in activities:\n",
    "        X = merge_dict[activity][activity + \"_mag_acc_\" + features[0]]\n",
    "        Y = merge_dict[activity][activity + \"_mag_acc_\" + features[1]]\n",
    "        Z = merge_dict[activity][activity + \"_mag_acc_\" + features[2]]\n",
    "        if activity == 'Idle':\n",
    "            _ = plot.scatter3D(X, Y, Z, label=activity, color=color[activity])\n",
    "        else:\n",
    "            _ = plot.scatter3D(X, Y, Z, label=activity, marker='x', color=color[activity])\n",
    "    plot.set_xlabel(features[0])\n",
    "    plot.set_ylabel(features[1])\n",
    "    plot.set_zlabel(features[2])\n",
    "    plot.legend()\n",
    "    \n",
    "\n",
    "activities=['Jumping', 'Running', 'Walking', 'Stairs', 'Idle']\n",
    "features=['mean','max','variance']\n",
    "plot_stage_4(activities, features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba649337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
